combi$Embarked[combi$Embarked ==""] <- "S"
which(combi$Embarked=="")
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
set.seed(415)
#read the data
train <- read.csv("~/Dropbox/Kaggle/Titanic/train.csv")
test <- read.csv("~/Dropbox/Kaggle/Titanic/test.csv")
train$traintest <- "train"
test$traintest<-"test"
test$Survived<- NA
#combine train and test set to do som operations on the columns
combi <- rbind(train, test)
#For random forest we should get rid of missing values (simple CART and Boosting trees know how to handle this)
#Getting rid of NA's can be done by first building a simple tree with the variable with missing values as the dependent.
#Age is missing some values
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
#Predict the Fare for the missing value
hallo<-combi[is.na(combi$Fare),]
Farefit <- rpart(Fare ~ Pclass + Sex + SibSp + Parch + Fare + Embarked+Age,
data=combi[!is.na(combi$Fare),], method="anova")
combi$Fare[is.na(combi$Fare)] <- predict(Farefit, combi[is.na(combi$Fare),])
#Set the Embarked for the missing values to Southhampton
which(combi$Embarked=="")
combi$Embarked[combi$Embarked ==""] <- "S"
which(combi$Embarked=="")
View(combi)
which(combi$Embarked=="")
combi$Embarked[combi$Embarked ==""] <- "S"
which(combi$Embarked=="")
table(combi$Embarked)
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
set.seed(415)
#read the data
train <- read.csv("~/Dropbox/Kaggle/Titanic/train.csv")
test <- read.csv("~/Dropbox/Kaggle/Titanic/test.csv")
train$traintest <- "train"
test$traintest<-"test"
test$Survived<- NA
#combine train and test set to do som operations on the columns
combi <- rbind(train, test)
#For random forest we should get rid of missing values (simple CART and Boosting trees know how to handle this)
#Getting rid of NA's can be done by first building a simple tree with the variable with missing values as the dependent.
#Age is missing some values
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
#Predict the Fare for the missing value
hallo<-combi[is.na(combi$Fare),]
Farefit <- rpart(Fare ~ Pclass + Sex + SibSp + Parch + Fare + Embarked+Age,
data=combi[!is.na(combi$Fare),], method="anova")
combi$Fare[is.na(combi$Fare)] <- predict(Farefit, combi[is.na(combi$Fare),])
#Set the Embarked for the missing values to Southhampton
which(combi$Embarked=="")
combi$Embarked[combi$Embarked ==""] <- "S"
table(combi$Embarked)
#Cabin or no cabin variable
combi$HasCabin = as.factor(sapply(combi$Cabin, function(x) if (x=="") 0 else 1))
#the formula for the model
formula <- as.factor(Survived) ~ HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
#split the data again in a train and test set
train <- combi[combi$traintest == "train",]
test <- combi[combi$traintest == "test",]
#Built a simple CART Tree
fit <- rpart(formula, data=train,method="class")
summary(combi)
summary(test)
#Plot the CART tree
fancyRpartPlot(fit)
#built a randomd Forest (for a random forest we first need to take care of missing values)
fit_rf <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch  + Embarked
, data=train, importance=TRUE, ntree=2000)
#plot the importance of the variables of the random forest
varImpPlot(fit_rf)
#Predict unknowns from the test set
test$Survived <- predict(fit_rf, test, type = "class")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
summary(submit)
View(combi)
View(combi)
combi$Name <- as.character(combi$Name)
combi$Title <- sub(' ','',sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]}))
View(combi)
prop.table(combi$Title)
table(combi$Title)
prop(table(combi$Title))
prop.table(combi$Title))
prop.table(combi$Title)
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
table(combi$Title)
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
table(combi$Title)
combi$Title <- as.factor(combi$Title)
combi$FamilySize <- combi$SibSp + combi$Parch + 1
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
set.seed(415)
#read the data
train <- read.csv("~/Dropbox/Kaggle/Titanic/train.csv")
test <- read.csv("~/Dropbox/Kaggle/Titanic/test.csv")
train$traintest <- "train"
test$traintest<-"test"
test$Survived<- NA
#combine train and test set to do som operations on the columns
combi <- rbind(train, test)
#convert the name from factor to character
combi$Name <- as.character(combi$Name)
#add a Title column to the data
combi$Title <- sub(' ','',sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]}))
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- as.factor(combi$Title)
table(combi$Title)
#Create familySize
combi$FamilySize <- combi$SibSp + combi$Parch + 1
#For random forest we should get rid of missing values (simple CART and Boosting trees know how to handle this)
#Getting rid of NA's can be done by first building a simple tree with the variable with missing values as the dependent.
#Age is missing some values
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
#Predict the Fare for the missing value
Farefit <- rpart(Fare ~ Pclass + Sex + SibSp + Parch + Fare + Embarked+Age,
data=combi[!is.na(combi$Fare),], method="anova")
combi$Fare[is.na(combi$Fare)] <- predict(Farefit, combi[is.na(combi$Fare),])
#Set the Embarked for the missing values to Southhampton
which(combi$Embarked=="")
combi$Embarked[combi$Embarked ==""] <- "S"
table(combi$Embarked)
#Cabin or no cabin variable
combi$HasCabin = as.factor(sapply(combi$Cabin, function(x) if (x=="") 0 else 1))
#the formula for the model
formula <- as.factor(Survived) ~ Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
#split the data again in a train and test set
train <- combi[combi$traintest == "train",]
test <- combi[combi$traintest == "test",]
#Built a simple CART Tree
fit <- rpart(formula, data=train,method="class")
#Plot the CART tree
fancyRpartPlot(fit)
#built a randomd Forest (for a random forest we first need to take care of missing values)
fit_rf <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch  + Embarked
, data=train, importance=TRUE, ntree=2000)
#plot the importance of the variables of the random forest
varImpPlot(fit_rf)
#Predict unknowns from the test set
test$Survived <- predict(fit_rf, test, type = "class")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
summary(submit)
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
table(combi$Surname)
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
table(combi$FamilyID)
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
table(combi$FamilyID)
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
table(combi$FamilyID)
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
set.seed(415)
#read the data
train <- read.csv("~/Dropbox/Kaggle/Titanic/train.csv")
test <- read.csv("~/Dropbox/Kaggle/Titanic/test.csv")
train$traintest <- "train"
test$traintest<-"test"
test$Survived<- NA
#combine train and test set to do som operations on the columns
combi <- rbind(train, test)
#convert the name from factor to character
combi$Name <- as.character(combi$Name)
#add a Title column to the data
combi$Title <- sub(' ','',sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]}))
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- as.factor(combi$Title)
table(combi$Title)
#Create familySize
combi$FamilySize <- combi$SibSp + combi$Parch + 1
#Create lastname variable
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
table(combi$FamilyID)
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
#For random forest we should get rid of missing values (simple CART and Boosting trees know how to handle this)
#Getting rid of NA's can be done by first building a simple tree with the variable with missing values as the dependent.
#Age is missing some values
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
#Predict the Fare for the missing value
Farefit <- rpart(Fare ~ Pclass + Sex + SibSp + Parch + Fare + Embarked+Age,
data=combi[!is.na(combi$Fare),], method="anova")
combi$Fare[is.na(combi$Fare)] <- predict(Farefit, combi[is.na(combi$Fare),])
#Set the Embarked for the missing values to Southhampton
which(combi$Embarked=="")
combi$Embarked[combi$Embarked ==""] <- "S"
table(combi$Embarked)
#Cabin or no cabin variable
combi$HasCabin = as.factor(sapply(combi$Cabin, function(x) if (x=="") 0 else 1))
#the formula for the model
formula <- as.factor(Survived) ~ FamilyID+Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
#split the data again in a train and test set
train <- combi[combi$traintest == "train",]
test <- combi[combi$traintest == "test",]
#Built a simple CART Tree
fit <- rpart(formula, data=train,method="class")
#Plot the CART tree
fancyRpartPlot(fit)
#built a randomd Forest (for a random forest we first need to take care of missing values)
fit_rf <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch  + Embarked
, data=train, importance=TRUE, ntree=2000)
#plot the importance of the variables of the random forest
varImpPlot(fit_rf)
#Predict unknowns from the test set
test$Survived <- predict(fit_rf, test, type = "class")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
summary(submit)
fit_rf <- randomForest(formula
, data=train, importance=TRUE, ntree=2000)
fit_rf <- randomForest(as.factor(Survived) ~ FamilyID+Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
, data=train, importance=TRUE, ntree=2000)
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
set.seed(415)
#read the data
train <- read.csv("~/Dropbox/Kaggle/Titanic/train.csv")
test <- read.csv("~/Dropbox/Kaggle/Titanic/test.csv")
train$traintest <- "train"
test$traintest<-"test"
test$Survived<- NA
#combine train and test set to do som operations on the columns
combi <- rbind(train, test)
#convert the name from factor to character
combi$Name <- as.character(combi$Name)
#add a Title column to the data
combi$Title <- sub(' ','',sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]}))
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- as.factor(combi$Title)
table(combi$Title)
#Create familySize
combi$FamilySize <- combi$SibSp + combi$Parch + 1
#Create lastname variable
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
table(combi$FamilyID)
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
#For random forest we should get rid of missing values (simple CART and Boosting trees know how to handle this)
#Getting rid of NA's can be done by first building a simple tree with the variable with missing values as the dependent.
#Age is missing some values
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
#Predict the Fare for the missing value
Farefit <- rpart(Fare ~ Pclass + Sex + SibSp + Parch + Fare + Embarked+Age,
data=combi[!is.na(combi$Fare),], method="anova")
combi$Fare[is.na(combi$Fare)] <- predict(Farefit, combi[is.na(combi$Fare),])
#Set the Embarked for the missing values to Southhampton
which(combi$Embarked=="")
combi$Embarked[combi$Embarked ==""] <- "S"
table(combi$Embarked)
#Cabin or no cabin variable
combi$HasCabin = as.factor(sapply(combi$Cabin, function(x) if (x=="") 0 else 1))
#the formula for the model
formula <- as.factor(Survived) ~ FamilyID+Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
#split the data again in a train and test set
train <- combi[combi$traintest == "train",]
test <- combi[combi$traintest == "test",]
#Built a simple CART Tree
fit <- rpart(formula, data=train,method="class")
#Plot the CART tree
fancyRpartPlot(fit)
#built a randomd Forest (for a random forest we first need to take care of missing values)
fit_rf <- randomForest(formula, data=train, importance=TRUE, ntree=2000)
#plot the importance of the variables of the random forest
varImpPlot(fit_rf)
#Predict unknowns from the test set
test$Survived <- predict(fit_rf, test, type = "class")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
summary(submit)
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(randomForest)
set.seed(415)
#read the data
train <- read.csv("~/Dropbox/Kaggle/Titanic/train.csv")
test <- read.csv("~/Dropbox/Kaggle/Titanic/test.csv")
train$traintest <- "train"
test$traintest<-"test"
test$Survived<- NA
#combine train and test set to do som operations on the columns
combi <- rbind(train, test)
#convert the name from factor to character
combi$Name <- as.character(combi$Name)
#add a Title column to the data
combi$Title <- sub(' ','',sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]}))
combi$Title[combi$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- as.factor(combi$Title)
table(combi$Title)
#Create familySize
combi$FamilySize <- combi$SibSp + combi$Parch + 1
#Create lastname variable
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
table(combi$FamilyID)
combi$FamilyID[combi$FamilySize <= 3] <- 'Small'
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 3,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
#For random forest we should get rid of missing values (simple CART and Boosting trees know how to handle this)
#Getting rid of NA's can be done by first building a simple tree with the variable with missing values as the dependent.
#Age is missing some values
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked,
data=combi[!is.na(combi$Age),], method="anova")
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
#Predict the Fare for the missing value
Farefit <- rpart(Fare ~ Pclass + Sex + SibSp + Parch + Fare + Embarked+Age,
data=combi[!is.na(combi$Fare),], method="anova")
combi$Fare[is.na(combi$Fare)] <- predict(Farefit, combi[is.na(combi$Fare),])
#Set the Embarked for the missing values to Southhampton
which(combi$Embarked=="")
combi$Embarked[combi$Embarked ==""] <- "S"
table(combi$Embarked)
#Cabin or no cabin variable
combi$HasCabin = as.factor(sapply(combi$Cabin, function(x) if (x=="") 0 else 1))
#the formula for the model
formula <- as.factor(Survived) ~ FamilyID+Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
#split the data again in a train and test set
train <- combi[combi$traintest == "train",]
test <- combi[combi$traintest == "test",]
#Built a simple CART Tree
fit <- rpart(formula, data=train,method="class")
#Plot the CART tree
fancyRpartPlot(fit)
#built a randomd Forest (for a random forest we first need to take care of missing values)
fit_rf <- randomForest(formula, data=train, importance=TRUE, ntree=2000)
#plot the importance of the variables of the random forest
varImpPlot(fit_rf)
#Predict unknowns from the test set
test$Survived <- predict(fit_rf, test, type = "class")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
summary(submit)
formula <- as.factor(Survived) ~ Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
#split the data again in a train and test set
train <- combi[combi$traintest == "train",]
test <- combi[combi$traintest == "test",]
#Built a simple CART Tree
fit <- rpart(formula, data=train,method="class")
#Plot the CART tree
fancyRpartPlot(fit)
#built a randomd Forest (for a random forest we first need to take care of missing values)
fit_rf <- randomForest(formula, data=train, importance=TRUE, ntree=2000)
#plot the importance of the variables of the random forest
varImpPlot(fit_rf)
#Predict unknowns from the test set
test$Survived <- predict(fit_rf, test, type = "class")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
library(gbm)
fit_gbm <- gbm(formula,n.trees = 200)
fit_gbm <- gbm(formula,data=train,n.trees = 200)
help(gbm)
fit_gbm <- gbm(formula,data=train,n.trees = 200,cv.folds = 10)
fit_gbm <- gbm(formula,data=train,n.trees = 200)
best.iter <- gbm.perf(gbm1,method="OOB")
best.iter <- gbm.perf(gbm,method="OOB")
best.iter <- gbm.perf(fit_gbm,method="OOB")
load("~/Dropbox/Novum/13. R/Spain Virgins/GBM.R")
fit_gbm <- gbm(formula,data=train,n.trees = 200,shrinkage=0.08, train.fraction=0.5)
best.iter <- gbm.perf(fit_gbm,method="test")
print(best.iter)
fit_gbm
fit_gbm <- gbm(formula,data=train,n.trees = 200,shrinkage=0.08, train.fraction=0.5)
fit_gbm
fit_gbm <- gbm(Survived ~ Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
,data=train,n.trees = 200,shrinkage=0.08, train.fraction=0.5)
fit_gbm
best.iter <- gbm.perf(fit_gbm,method="test")
print(best.iter)
fit_gbm <- gbm(Survived ~ FamilyID+Title+FamilySize+HasCabin+Pclass + Sex + Age + SibSp + Parch + Fare + Embarked+Fare
,data=train,n.trees = 200,shrinkage=0.08, train.fraction=0.5)
fit_gbm
# check performance using an out-of-bag estimator
# OOB underestimates the optimal number of iterations
best.iter <- gbm.perf(fit_gbm,method="test")
print(best.iter)
test$Survived <- predict(fit_gbm, test, type = "class")
test$Survived <- predict(fit_gbm, test, type = "response")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = test$Survived)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
summary(submit)
Survived_RF <- predict(fit_rf, test, type = "class")
#GBM: Predict unknowns from the test set
Survived_GBM <- predict(fit_gbm, test, type = "response")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_RF)
write.csv(submit, file = "randomforest.csv", row.names = FALSE)
summary(submit)
#Submit GBM to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_GBM)
write.csv(submit, file = "gbm.csv", row.names = FALSE)
summary(submit)
Survived_GBM <- predict(fit_gbm, test, type = "class")
Survived_GBM <- predict.gbm(fit_gbm, test, type = "link")
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_RF)
write.csv(submit, file = "randomforest.csv", row.names = FALSE)
summary(submit)
#Submit GBM to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_GBM)
write.csv(submit, file = "gbm.csv", row.names = FALSE)
summary(submit)
Survived_GBM <- predict.gbm(fit_gbm, test, type = "response")
Survived_GBM <- sapply(x,function(x) if (Survived_GBM > 0.5) 1 else 0)
Survived_GBM <- sapply(Survived_GBM,function(x) if (x > 0.5) 1 else 0)
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_GBM)
write.csv(submit, file = "gbm.csv", row.names = FALSE)
summary(submit)
Survived_GBM <- as.factor(sapply(Survived_GBM,function(x) if (x > 0.5) 1 else 0))
#Submit results to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_GBM)
write.csv(submit, file = "gbm.csv", row.names = FALSE)
summary(submit)
summary(submit)
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_RF)
write.csv(submit, file = "randomforest.csv", row.names = FALSE)
summary(submit)
#Submit GBM to kaggle
submit <- data.frame(PassengerId = test$PassengerId, Survived = Survived_GBM)
write.csv(submit, file = "gbm.csv", row.names = FALSE)
summary(submit)
fit_rf <- randomForest(train, data=train, importance=TRUE, ntree=2000)
dataSet = combi[combi$Title, comb$Sex]
dataSet = combi[combi$Title, combi$Sex]
View(dataSet)
dataSet = combi[combi$Title combi$Sex]
dataSet <- data.frame[combi$Title,combi$Sex]
dataSet <- data.frame[Title = combi$Title,Sex = combi$Sex]
dataSet <- data.frame(combi$Title,combi$Sex)
View(dataSet)
dataSet <- data.frame(Title = combi$Title,Sex = combi$Sex, Survived=combi$Survived)
fit_rf <- randomForest(dataSet, data=train, importance=TRUE, ntree=2000)
dataSet <- data.frame(Title = train$Title,Sex = train$Sex, Survived=train$Survived)
#built a randomd Forest (for a random forest we first need to take care of missing values)
fit_rf <- randomForest(dataSet, data=train, importance=TRUE, ntree=2000)
#plot the importance of the variables of the random forest
varImpPlot(fit_rf)
dataSet <- data.frame([train$Title],[train$Sex])
dataSet <- data.frame([train$Title],[train$Sex])
dataSet <- data.frame(train$Title,[train$Sex])
dataSet <- [train$Title,train$Sex]
dataSet <- (train$Title,train$Sex)
dataSet <- (train$Title+train$Sex)
dataSet <- (train$Title train$Sex)
dataSet <- [train$Title train$Sex]
fit_rf <- randomForest(dataSet, data=train, importance=TRUE, ntree=2000, type='unsupervised' )
fit_rf
install.packages("som")
library(som)
som(train)
help(som)
